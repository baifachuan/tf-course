{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0050 cost= 0.077130280 W= 0.243226 b= 0.847277\n",
      "Epoch: 0100 cost= 0.077114716 W= 0.243604 b= 0.844552\n",
      "Epoch: 0150 cost= 0.077100903 W= 0.243961 b= 0.84199\n",
      "Epoch: 0200 cost= 0.077088661 W= 0.244296 b= 0.839579\n",
      "Epoch: 0250 cost= 0.077077806 W= 0.244611 b= 0.837311\n",
      "Epoch: 0300 cost= 0.077068195 W= 0.244907 b= 0.83518\n",
      "Epoch: 0350 cost= 0.077059627 W= 0.245186 b= 0.833174\n",
      "Epoch: 0400 cost= 0.077052049 W= 0.245448 b= 0.831287\n",
      "Epoch: 0450 cost= 0.077045336 W= 0.245695 b= 0.829513\n",
      "Epoch: 0500 cost= 0.077039346 W= 0.245927 b= 0.827845\n",
      "Epoch: 0550 cost= 0.077034056 W= 0.246145 b= 0.826275\n",
      "Epoch: 0600 cost= 0.077029318 W= 0.24635 b= 0.824798\n",
      "Epoch: 0650 cost= 0.077025153 W= 0.246543 b= 0.82341\n",
      "Epoch: 0700 cost= 0.077021457 W= 0.246725 b= 0.822105\n",
      "Epoch: 0750 cost= 0.077018134 W= 0.246895 b= 0.820877\n",
      "Epoch: 0800 cost= 0.077015206 W= 0.247056 b= 0.819722\n",
      "Epoch: 0850 cost= 0.077012584 W= 0.247207 b= 0.818635\n",
      "Epoch: 0900 cost= 0.077010266 W= 0.247349 b= 0.817611\n",
      "Epoch: 0950 cost= 0.077008210 W= 0.247483 b= 0.816653\n",
      "Epoch: 1000 cost= 0.077006370 W= 0.247608 b= 0.815749\n",
      "Optimization Finished!\n",
      "Training cost= 0.0770064 W= 0.247608 b= 0.815749 \n",
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To exit: use 'exit', 'quit', or Ctrl-D.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rng = numpy.random\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "display_step = 50\n",
    "\n",
    "# Training Data\n",
    "train_X = numpy.asarray([3.3, 4.4, 5.5, 6.71, 6.93, 4.168, 9.779, 6.182, 7.59, 2.167,\n",
    "                         7.042, 10.791, 5.313, 7.997, 5.654, 9.27, 3.1])\n",
    "train_Y = numpy.asarray([1.7, 2.76, 2.09, 3.19, 1.694, 1.573, 3.366, 2.596, 2.53, 1.221,\n",
    "                         2.827, 3.465, 1.65, 2.904, 2.42, 2.94, 1.3])\n",
    "\n",
    "plt.plot(train_X, train_Y, 'ro', label='Original data')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "n_samples = train_X.shape[0]\n",
    "\n",
    "# tf Graph Input\n",
    "X = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(rng.randn(), name=\"weight\")\n",
    "b = tf.Variable(rng.randn(), name=\"bias\")\n",
    "\n",
    "# Construct a linear model y = X * W + b\n",
    "pred = tf.add(tf.multiply(X, W), b)\n",
    "\n",
    "# Mean squared error\n",
    "cost = tf.reduce_sum(tf.pow(pred - Y, 2)) / (2 * n_samples)\n",
    "# Gradient descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        for (x, y) in zip(train_X, train_Y):\n",
    "            sess.run(optimizer, feed_dict={X: x, Y: y})\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if (epoch + 1) % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n",
    "            print(\"Epoch:\", '%04d' % (epoch + 1), \"cost=\", \"{:.9f}\".format(c), \\\n",
    "                  \"W=\", sess.run(W), \"b=\", sess.run(b))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n",
    "    print(\"Training cost=\", training_cost, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n')\n",
    "\n",
    "    # Graphic display\n",
    "    plt.plot(train_X, train_Y, 'ro', label='Original data')\n",
    "    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Testing example, as requested (Issue #2)\n",
    "    test_X = numpy.asarray([6.83, 4.668, 8.9, 7.91, 5.7, 8.7, 3.1, 2.1])\n",
    "    test_Y = numpy.asarray([1.84, 2.273, 3.2, 2.831, 2.92, 3.24, 1.35, 1.03])\n",
    "\n",
    "    print(\"Testing... (Mean square loss Comparison)\")\n",
    "    testing_cost = sess.run(\n",
    "        tf.reduce_sum(tf.pow(pred - Y, 2)) / (2 * test_X.shape[0]),\n",
    "        feed_dict={X: test_X, Y: test_Y})  # same function as cost above\n",
    "    print(\"Testing cost=\", testing_cost)\n",
    "    print(\"Absolute mean square loss difference:\", abs(\n",
    "        training_cost - testing_cost))\n",
    "\n",
    "    plt.plot(test_X, test_Y, 'bo', label='Testing data')\n",
    "    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
